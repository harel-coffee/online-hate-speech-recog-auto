{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../data/dataset.csv\n",
    "!cat ../data/en/hasoc2019/hasoc2019.csv >> ../data/dataset.csv\n",
    "!cat ../data/en/hate_speech_icwsm18/nhsm.csv >> ../data/dataset.csv\n",
    "!cat ../data/en/hate-speech-and-offensive-language/t_davidson.csv >> ../data/dataset.csv\n",
    "!cat ../data/en/ousidhoum-etal-multilingual-hate-speech-2019/ousidhoum.csv >> ../data/dataset.csv\n",
    "!cat ../data/en/semeval2019/semeval2019.csv >> ../data/dataset.csv\n",
    "\n",
    "!rm ../data/dataset-hi.csv\n",
    "!rm ../data/dataset-hi-cdmx.csv\n",
    "!cat ../data/hi/hasoc2019/hi-hasoc2019.csv >> ../data/dataset-hi.csv\n",
    "!cat ../data/hi/Hinglish-Offensive-Text-Classification/hi-code-mixed-pmathur.csv >> ../data/dataset-hi-cdmx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install ekphrasis\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import feature_generation as fg\n",
    "import base_line_LR as lr\n",
    "from utils.emoji import emoji_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "(50379, 4)\n",
      "              class      text_len\n",
      "count  50379.000000  50379.000000\n",
      "mean       1.122134     16.847476\n",
      "std        0.878632     10.154718\n",
      "min        0.000000      1.000000\n",
      "25%        0.000000      9.000000\n",
      "50%        1.000000     15.000000\n",
      "75%        2.000000     22.000000\n",
      "max        2.000000     95.000000\n"
     ]
    }
   ],
   "source": [
    "pre = fg.features(lang='en')\n",
    "df_en = pd.read_csv('../data/dataset.csv')\n",
    "df_en = df_en.dropna()\n",
    "df_en.drop(df_en[(df_en['text_id'] == 'text_id')].index,inplace=True)\n",
    "df_en.drop(df_en[(df_en['hate'] == 'HS')].index,inplace=True)\n",
    "df_en.rename(columns={'hate':'class'},inplace=True)\n",
    "df_en[\"class\"] = df_en[\"class\"].astype(int)\n",
    "df_en['text_len'] = df_en.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_en = df_en[df_en['text_len']<200]\n",
    "print(df_en.shape)\n",
    "print(df_en.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 50379\n",
      "Hateful (class) = 1: 10736 ( 21.310466662696758 %)\n",
      "Offensive (class) = 2: 22898 ( 45.45147779828897 %)\n",
      "\n",
      "****\n",
      "\n",
      "**Hateful examples (class) = 1\n",
      "[\"A gangster sets out to fulfill his father’s dream of becoming a doctor.    Doctor's in #WestBengal be like #munna_bhai_MBBS    #DoctorsFightBack #DoctorsStrike #DoctorsUnderOppression   @MamataOfficial https://t.co/lZQcStQ2Md\"]\n",
      "\n",
      "**Offensive examples (class) = 2\n",
      "['!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f49354bc400>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total = df_en.shape[0]\n",
    "gp = df_en.groupby(['class'])['text_id'].count()\n",
    "hate = gp[1]\n",
    "offensive = gp[2]\n",
    "print(\"Size of dataset:\", total)\n",
    "print(\"Hateful (class) = 1:\", hate, \"(\",hate/total*100,\"%)\")\n",
    "print(\"Offensive (class) = 2:\",offensive, \"(\",offensive/total*100,\"%)\")\n",
    "print(\"\\n****\\n\")\n",
    "print('**Hateful examples (class) = 1')\n",
    "print(list(df_en[df_en['class']==1]['text'][0:1]))\n",
    "\n",
    "print('\\n**Offensive examples (class) = 2')\n",
    "print(list(df_en[df_en['class']==2]['text'][0:1]))\n",
    "gp.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from ekphrasis.dicts.noslang.slang import slang\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons,slang]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en['ekphrasis_clean_text'] = df_en.apply(lambda x: \" \".join(text_processor.pre_process_doc(x.text)),axis=1)\n",
    "df_en['basic_clean_text'] = df_en.apply(lambda x: pre.preprocess(x.text), axis = 1)\n",
    "df_en.to_csv('../data/dataset_en.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why the #DoctorsFightBack is not just about violence unleashed on them ? Its time to address faltering justice systems, crippled health systems and broken dreams  https://t.co/S2akvvDDlY\n",
      "why the <hashtag> doctors fight back </hashtag> is not just about violence unleashed on them ? its time to address faltering justice systems , crippled health systems and broken dreams <url>\n"
     ]
    }
   ],
   "source": [
    "print(df_en['text'][100])\n",
    "print(df_en['ekphrasis_clean_text'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why the #DoctorsFightBack is not just about violence unleashed on them ? Its time to address faltering justice systems, crippled health systems and broken dreams  https://t.co/S2akvvDDlY\n",
      "why the doctors fight back not just about violence unleashed them ? its time address faltering justice systems , crippled health systems and broken dreams\n"
     ]
    }
   ],
   "source": [
    "print(df_en['text'][100])\n",
    "print(df_en['basic_clean_text'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.learner.MultiBatchEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.AWD_LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.EmbeddingDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.WeightDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.RNNDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'fastai.text.learner.PoolingLinearClassifier' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "(9330, 3)\n",
      "            class\n",
      "count  9330.00000\n",
      "mean      0.52926\n",
      "std       0.49917\n",
      "min       0.00000\n",
      "25%       0.00000\n",
      "50%       1.00000\n",
      "75%       1.00000\n",
      "max       1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "pre = fg.features(lang='hi')\n",
    "df_hi = pd.read_csv('../data/dataset-hi.csv')\n",
    "print(df_hi.shape)\n",
    "df_hi.drop(df_hi[(df_hi['text_id'] == 'text_id')].index,inplace=True)\n",
    "df_hi.drop(df_hi[(df_hi['hate'] == 'HS')].index,inplace=True)\n",
    "df_hi.rename(columns={'hate':'class'},inplace=True)\n",
    "print(df_hi.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 9330\n",
      "Hateful (class) = 1: 4938 ( 52.926045016077175 %)\n",
      "\n",
      "****\n",
      "\n",
      "**Hateful examples (class) = 1\n",
      "['ये लिटन की गाँड में लिप्टन की चाय डालता हूँ अभी विथ गर्म केतली ']\n"
     ]
    }
   ],
   "source": [
    "total = df_hi.shape[0]\n",
    "gp = df_hi.groupby(['class'])['text_id'].count()\n",
    "hate = gp[1]\n",
    "print(\"Size of dataset:\", total)\n",
    "print(\"Hateful (class) = 1:\", hate, \"(\",hate/total*100,\"%)\")\n",
    "print(\"\\n****\\n\")\n",
    "print('**Hateful examples (class) = 1')\n",
    "print(list(df_hi[df_hi['class']==1]['text'][0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi['text'] = df_hi.apply(lambda x: emoji_clean(x.text), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi['ekphrasis_clean_text'] = df_hi.apply(lambda x: \" \".join(text_processor.pre_process_doc(x.text)),axis=1)\n",
    "df_hi['basic_clean_text'] = df_hi.apply(lambda x: pre.preprocess(x.text), axis = 1)\n",
    "df_hi.to_csv('../data/dataset_hi.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ऑफिसियल मीटिंग्स में अब नो बिस्किट  केवल हेल्थी स्नैक्स:लाई चना,भुना चना,खजूर,काजू,बादाम,अखरोट ही दिया जायेगा  #डॉहर्षवर्द्धन MOH    आपने चाय के लिए कुछ नही बताया   पीनी है, कि नही पीनी है \n",
      "ऑफ ि स ि यल म ी ट ि ं ग ् स म े ं अब न ो ब ि स ् क ि ट क े वल ह े ल ् थ ी स ् न ै क ् स : ल ा ई चन ा , भ ु न ा चन ा , खज ू र , क ा ज ू , ब ा द ा म , अखर ो ट ह ी द ि य ा ज ा य े ग ा <hashtag> ड </hashtag> ॉ हर ् षवर ् द ् धन <allcaps> Medal Of Honor </allcaps> आपन े च ा य क े ल ि ए क ु छ नह ी बत ा य ा प ी न ी ह ै , क ि नह ी प ी न ी ह ै\n"
     ]
    }
   ],
   "source": [
    "print(df_hi['text'][100])\n",
    "print(df_hi['ekphrasis_clean_text'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ऑफिसियल मीटिंग्स में अब नो बिस्किट  केवल हेल्थी स्नैक्स:लाई चना,भुना चना,खजूर,काजू,बादाम,अखरोट ही दिया जायेगा  #डॉहर्षवर्द्धन MOH    आपने चाय के लिए कुछ नही बताया   पीनी है, कि नही पीनी है \n",
      "ऑफिस ियल मीटिंग में अब नो बिस् किट केवल हेल्थ स् ैक्स : लाई चना , चना , जूर , , बाद , ही दिया जायेगा # र्ष वर्द्धन all cap / all cap आपने चाय के लिए कुछ नही बताया पी है , कि नही पी है\n"
     ]
    }
   ],
   "source": [
    "print(df_hi['text'][100])\n",
    "print(df_hi['basic_clean_text'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code mixed Hindi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "(3189, 3)\n",
      "             class\n",
      "count  3189.000000\n",
      "mean      1.201944\n",
      "std       0.929772\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       2.000000\n",
      "75%       2.000000\n",
      "max       2.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "pre = fg.features(lang='en')\n",
    "df_hi_cdmx = pd.read_csv('../data/dataset-hi-cdmx.csv')\n",
    "print(df_hi_cdmx.shape)\n",
    "df_hi_cdmx.drop(df_hi_cdmx[(df_hi_cdmx['text_id'] == 'text_id')].index,inplace=True)\n",
    "df_hi_cdmx.drop(df_hi_cdmx[(df_hi_cdmx['hate'] == 'HS')].index,inplace=True)\n",
    "df_hi_cdmx.rename(columns={'hate':'class'},inplace=True)\n",
    "print(df_hi_cdmx.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 3189\n",
      "Hateful (class) = 1: 303 ( 9.501411100658514 %)\n",
      "\n",
      "****\n",
      "\n",
      "**Hateful examples (class) = 1\n",
      "['@InviSibleSold @mabkhan86 @dridadahn Main jutt Punjabi hoon aur paka N league. Madarchod Imran ki Punjab say nafrat clear hai.', 'RT @AnshKSpeaks: Screw the law of the land. If I find this chutiya Madarchod Mulla I will Lynch him, murder him, cut into millions of pieces and Ha\\\\xe2\\\\x80\\\\xa6', \"*Virat and Anushka's future kid*\\\\n\\\\nAnushka: Mamma bolo beta, mammaaaa\\\\n\\\\nKid: Mm.. Ma.. Maa.. Madarchod!\", '@dasraghubar @narendramodi @AmitShah @BJP4India @BJPLive @BJP4Jharkhand Madarchod brahmno se mafi mango', '@NANGI_POOJA Madarchod musalman aaiysha aur wo hai', '@M_walim @ICC @imVkohli @AnushkaSharma Teri ammi ko chodne wala insaan hai ye icc kya pure world isko badhai dekha bc hat mulle madarchod', '@girishalva @garuna73 I never donate to any madarchod hindu priests, they are chors.', 'Bhak Machod Mullo Ke Abbu  @bewak_sanki543 @milkygaay @Dilli_Ka_Maalik @ArvindKrejriwal @ashu3page @AamAadmiParty\\\\xe2\\\\x80\\\\xa6 https://t.co/K1pRnRhz0V', '@_R_aHu_L_ @Mk56Kaur bhadwe ki aulad ho tum sale madarchod ki wajah se ye zait failta hai hindu muslim ka bhen ke t\\\\xe2\\\\x80\\\\xa6 https://t.co/nbdEzBGmu1', '@NaamHiKafiHay Teri maa Randi Madarchod Saale Pakistani']\n"
     ]
    }
   ],
   "source": [
    "total = df_hi_cdmx.shape[0]\n",
    "gp = df_hi_cdmx.groupby(['class'])['text_id'].count()\n",
    "hate = gp[1]\n",
    "print(\"Size of dataset:\", total)\n",
    "print(\"Hateful (class) = 1:\", hate, \"(\",hate/total*100,\"%)\")\n",
    "print(\"\\n****\\n\")\n",
    "print('**Hateful examples (class) = 1')\n",
    "print(list(df_hi_cdmx[df_hi_cdmx['class']==1]['text'][0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi_cdmx['text'] = df_hi_cdmx.apply(lambda x: emoji_clean(x.text), axis=1) \n",
    "\n",
    "df_hi_cdmx['ekphrasis_clean_text'] = df_hi_cdmx.apply(lambda x: \" \".join(text_processor.pre_process_doc(x.text)),axis=1)\n",
    "df_hi_cdmx['basic_clean_text'] = df_hi_cdmx.apply(lambda x: pre.preprocess(x.text), axis = 1)\n",
    "df_hi_cdmx.to_csv('../data/dataset_hi_cdmx.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AvijitEmmi Bahenchod .... experienced lagte ho bhai bhot face with tears of joy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'user bahenchod . experienced lagte hold on bhai bhot face with tears joy'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_hi_cdmx['text'][100])\n",
    "df_hi_cdmx['basic_clean_text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AvijitEmmi Bahenchod .... experienced lagte ho bhai bhot face with tears of joy\n",
      "<user> bahenchod . <repeated> experienced lagte hold on bhai bhot face with tears of joy\n"
     ]
    }
   ],
   "source": [
    "print(df_hi_cdmx['text'][100])\n",
    "print(df_hi_cdmx['ekphrasis_clean_text'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LR Baseline Model - EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/import/linux/python/3.6.9/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n",
      "/import/linux/python/3.6.9/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "text = df_en.text\n",
    "feat = fg.features(lang='en')\n",
    "M,fnames = feat.get_feature_array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df_en['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "logreg = lr.LR()\n",
    "model = logreg.train(X,y,max_iter=5000, test_size=0.2,param_grid=[{}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.gen_report(y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.gen_confusion_matrix(y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LR Baseline Model - HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_hi.text\n",
    "feat = fg.features(lang='hi')\n",
    "M,fnames = feat.get_feature_array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df_hi['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = lr.LR()\n",
    "model = logreg.train(X,y,max_iter=5000, test_size=0.2,param_grid=[{}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.gen_report(y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.gen_confusion_matrix(y_pred = y_pred, classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LR Baseline Model - HI - Code Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_hi_cdmx.text\n",
    "feat = fg.features(lang='en')\n",
    "M,fnames = feat.get_feature_array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df_hi_cdmx['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = lr.LR()\n",
    "model = logreg.train(X,y,max_iter=3000, test_size=0.2,param_grid=[{}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.gen_report(y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.gen_confusion_matrix(y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
