{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Emoticons ...\n",
      "Reading Slangs ...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from base_line_DNN import CNN_LSTM as network\n",
    "from base_line_DNN import ProcessData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.read_csv('../data/dataset_en.csv')\n",
    "df_en[\"class\"] = df_en[\"class\"].astype(int)\n",
    "df_en = df_en.dropna() # drop any rotokenizer_testws with nans\n",
    "df_en.drop(df_en.loc[df_en['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_en.drop(df_en.loc[df_en['class'] == 'HS'].index,inplace=True)\n",
    "df_en['text_len'] = df_en.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_en = df_en[df_en['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 137/50369 [00:00<00:36, 1364.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50369/50369 [00:31<00:00, 1577.49it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_en, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 43561, array([2, 1, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /homes/nv304/virtpy3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 73, 16)            696976    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 73, 128)           10368     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 712,937\n",
      "Trainable params: 712,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=50, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /homes/nv304/virtpy3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 36265 samples, validate on 4030 samples\n",
      "Epoch 1/50\n",
      "36265/36265 [==============================] - 17s 470us/step - loss: 0.7796 - accuracy: 0.6594 - val_loss: 0.7078 - val_accuracy: 0.7136\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71365, saving model to ../model/en_weights.best.hdf5\n",
      "Epoch 2/50\n",
      "36265/36265 [==============================] - 14s 388us/step - loss: 0.6021 - accuracy: 0.7586 - val_loss: 0.6646 - val_accuracy: 0.7293\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71365 to 0.72928, saving model to ../model/en_weights.best.hdf5\n",
      "Epoch 3/50\n",
      "36265/36265 [==============================] - 13s 367us/step - loss: 0.4825 - accuracy: 0.8152 - val_loss: 0.6875 - val_accuracy: 0.7122\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72928\n",
      "Epoch 4/50\n",
      "36265/36265 [==============================] - 13s 355us/step - loss: 0.3926 - accuracy: 0.8553 - val_loss: 0.7423 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72928\n",
      "Epoch 5/50\n",
      "36265/36265 [==============================] - 13s 366us/step - loss: 0.3265 - accuracy: 0.8820 - val_loss: 0.7949 - val_accuracy: 0.6888\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72928\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/en_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi = pd.read_csv('../data/dataset_hi.csv')\n",
    "df_hi[\"class\"] = df_hi[\"class\"].astype(int)\n",
    "df_hi = df_hi.dropna() # drop any rotokenizer_testws with nans\n",
    "df_hi.drop(df_hi.loc[df_hi['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_hi.drop(df_hi.loc[df_hi['class'] == 'HS'].index,inplace=True)\n",
    "df_hi['text_len'] = df_hi.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_hi = df_hi[df_hi['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9330 [00:00<13:51, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9330/9330 [13:30<00:00, 11.51it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_hi, lang='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 7636, array([0, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 199, 16)           122176    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 199, 128)          10368     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 138,126\n",
      "Trainable params: 138,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=10, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6717 samples, validate on 747 samples\n",
      "Epoch 1/10\n",
      "6717/6717 [==============================] - 7s 1ms/step - loss: 0.5109 - accuracy: 0.7439 - val_loss: 0.4480 - val_accuracy: 0.8153\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81526, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 2/10\n",
      "6717/6717 [==============================] - 6s 915us/step - loss: 0.2540 - accuracy: 0.9062 - val_loss: 0.3310 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81526 to 0.87015, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 3/10\n",
      "6717/6717 [==============================] - 6s 909us/step - loss: 0.1441 - accuracy: 0.9558 - val_loss: 0.2854 - val_accuracy: 0.8969\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87015 to 0.89692, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 4/10\n",
      "6717/6717 [==============================] - 6s 926us/step - loss: 0.0976 - accuracy: 0.9717 - val_loss: 0.2641 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.89692 to 0.90495, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 5/10\n",
      "6717/6717 [==============================] - 6s 876us/step - loss: 0.0698 - accuracy: 0.9820 - val_loss: 0.2572 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.90495 to 0.91566, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 6/10\n",
      "6717/6717 [==============================] - 6s 932us/step - loss: 0.0548 - accuracy: 0.9860 - val_loss: 0.2501 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91566\n",
      "Epoch 7/10\n",
      "6717/6717 [==============================] - 6s 894us/step - loss: 0.0424 - accuracy: 0.9896 - val_loss: 0.2660 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91566 to 0.92503, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 8/10\n",
      "6717/6717 [==============================] - 6s 900us/step - loss: 0.0324 - accuracy: 0.9927 - val_loss: 0.2863 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.92503\n",
      "Epoch 9/10\n",
      "6717/6717 [==============================] - 6s 934us/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.2902 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92503\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/hi_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi-Code Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'text_id', 'ekphrasis_clean_text', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_hi_cdmx = pd.read_csv('../data/dataset_hi_cdmx.csv')\n",
    "df_hi_cdmx[\"class\"] = df_hi_cdmx[\"class\"].astype(int)\n",
    "df_hi_cdmx = df_hi_cdmx.dropna() # drop any rotokenizer_testws with nans\n",
    "df_hi_cdmx = df_hi_cdmx.drop(['text'],axis=1)\n",
    "df_hi_cdmx = df_hi_cdmx.rename(columns={'basic_clean_text':'text'})\n",
    "print(df_hi_cdmx.columns)\n",
    "df_hi_cdmx.drop(df_hi_cdmx.loc[df_hi_cdmx['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_hi_cdmx.drop(df_hi_cdmx.loc[df_hi_cdmx['class'] == 'HS'].index,inplace=True)\n",
    "df_hi_cdmx['text_len'] = df_hi_cdmx.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_hi_cdmx = df_hi_cdmx[df_hi_cdmx['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 179/3161 [00:00<00:01, 1784.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3161/3161 [00:01<00:00, 1837.30it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_hi_cdmx, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 5997, array([2, 0, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 48, 16)            95952     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 48, 128)           10368     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 111,913\n",
      "Trainable params: 111,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=10, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2275 samples, validate on 253 samples\n",
      "Epoch 1/10\n",
      "2275/2275 [==============================] - 1s 547us/step - loss: 0.9798 - accuracy: 0.5437 - val_loss: 0.9119 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58498, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 2/10\n",
      "2275/2275 [==============================] - 1s 347us/step - loss: 0.8977 - accuracy: 0.5560 - val_loss: 0.8877 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.58498\n",
      "Epoch 3/10\n",
      "2275/2275 [==============================] - 1s 323us/step - loss: 0.8044 - accuracy: 0.5560 - val_loss: 0.8191 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.58498\n",
      "Epoch 4/10\n",
      "2275/2275 [==============================] - 1s 322us/step - loss: 0.6232 - accuracy: 0.7262 - val_loss: 0.7269 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.58498 to 0.74704, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 5/10\n",
      "2275/2275 [==============================] - 1s 333us/step - loss: 0.4107 - accuracy: 0.9187 - val_loss: 0.6248 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74704 to 0.78656, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 6/10\n",
      "2275/2275 [==============================] - 1s 322us/step - loss: 0.2735 - accuracy: 0.9508 - val_loss: 0.5869 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78656\n",
      "Epoch 7/10\n",
      "2275/2275 [==============================] - 1s 312us/step - loss: 0.1926 - accuracy: 0.9662 - val_loss: 0.5690 - val_accuracy: 0.7628\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78656\n",
      "Epoch 8/10\n",
      "2275/2275 [==============================] - 1s 318us/step - loss: 0.1478 - accuracy: 0.9710 - val_loss: 0.5713 - val_accuracy: 0.7549\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78656\n",
      "Epoch 9/10\n",
      "2275/2275 [==============================] - 1s 349us/step - loss: 0.1218 - accuracy: 0.9758 - val_loss: 0.6599 - val_accuracy: 0.7233\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.78656\n",
      "Epoch 10/10\n",
      "2275/2275 [==============================] - 1s 322us/step - loss: 0.0988 - accuracy: 0.9780 - val_loss: 0.6061 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78656\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/hi_cdmx_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 595.02it/s]\n"
     ]
    }
   ],
   "source": [
    "text = ['@AvijitEmmi Bahenchod .... experienced lagte ho bhai bhot face with tears of joy']\n",
    "test_data = ProcessData(df=text, lang='en', max_seq_len=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2]), array([[0.079639, 0.121737, 0.82869 ]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network()\n",
    "net.predict(model_path='../model/hi_cdmx_weights.best.hdf5',x=test_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
