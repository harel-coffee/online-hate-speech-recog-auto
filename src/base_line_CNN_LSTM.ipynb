{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from base_line_DNN import CNN_LSTM as network\n",
    "from base_line_DNN import ProcessData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.read_csv('../data/dataset_en.csv')\n",
    "df_en[\"class\"] = df_en[\"class\"].astype(int)\n",
    "df_en = df_en.dropna() # drop any rotokenizer_testws with nans\n",
    "df_en.drop(df_en.loc[df_en['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_en.drop(df_en.loc[df_en['class'] == 'HS'].index,inplace=True)\n",
    "df_en['text_len'] = df_en.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_en = df_en[df_en['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50369/50369 [00:31<00:00, 1592.09it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_en, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 43405, array([2, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 73, 16)            694480    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 73, 128)           10368     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 710,441\n",
      "Trainable params: 710,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=50, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36265 samples, validate on 4030 samples\n",
      "Epoch 1/50\n",
      "36265/36265 [==============================] - 17s 467us/step - loss: 0.7660 - accuracy: 0.6658 - val_loss: 0.7213 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72481, saving model to ../model/en_weights.best.hdf5\n",
      "Epoch 2/50\n",
      "36265/36265 [==============================] - 16s 436us/step - loss: 0.5813 - accuracy: 0.7658 - val_loss: 0.6942 - val_accuracy: 0.7144\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72481\n",
      "Epoch 3/50\n",
      "36265/36265 [==============================] - 17s 460us/step - loss: 0.4646 - accuracy: 0.8221 - val_loss: 0.6910 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72481\n",
      "Epoch 4/50\n",
      "36265/36265 [==============================] - 16s 440us/step - loss: 0.3872 - accuracy: 0.8559 - val_loss: 0.7228 - val_accuracy: 0.7017\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72481\n",
      "Epoch 5/50\n",
      "36265/36265 [==============================] - 16s 432us/step - loss: 0.3239 - accuracy: 0.8804 - val_loss: 0.7848 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72481\n",
      "Epoch 6/50\n",
      "36265/36265 [==============================] - 16s 450us/step - loss: 0.2791 - accuracy: 0.8984 - val_loss: 0.8391 - val_accuracy: 0.6826\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.72481\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/en_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/nv304/virtpy3/lib/python3.6/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "df_hi = pd.read_csv('../data/dataset_hi.csv')\n",
    "df_hi[\"class\"] = df_hi[\"class\"].astype(int)\n",
    "df_hi = df_hi.dropna() # drop any rotokenizer_testws with nans\n",
    "df_hi.drop(df_hi.loc[df_hi['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_hi.drop(df_hi.loc[df_hi['class'] == 'HS'].index,inplace=True)\n",
    "df_hi['text_len'] = df_hi.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_hi = df_hi[df_hi['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9330/9330 [14:19<00:00, 10.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_hi, lang='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 7632, array([0, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /homes/nv304/virtpy3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 199, 16)           122112    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 199, 128)          10368     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 138,062\n",
      "Trainable params: 138,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=10, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /homes/nv304/virtpy3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6717 samples, validate on 747 samples\n",
      "Epoch 1/10\n",
      "6717/6717 [==============================] - 9s 1ms/step - loss: 0.5193 - accuracy: 0.7371 - val_loss: 0.4448 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83668, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 2/10\n",
      "6717/6717 [==============================] - 7s 1ms/step - loss: 0.2640 - accuracy: 0.9006 - val_loss: 0.3395 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.83668 to 0.88086, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 3/10\n",
      "6717/6717 [==============================] - 8s 1ms/step - loss: 0.1517 - accuracy: 0.9530 - val_loss: 0.2614 - val_accuracy: 0.9116\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88086 to 0.91165, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 4/10\n",
      "6717/6717 [==============================] - 7s 1ms/step - loss: 0.1009 - accuracy: 0.9723 - val_loss: 0.2445 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91165 to 0.91700, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 5/10\n",
      "6717/6717 [==============================] - 7s 1ms/step - loss: 0.0738 - accuracy: 0.9812 - val_loss: 0.2210 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91700 to 0.92369, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 6/10\n",
      "6717/6717 [==============================] - 8s 1ms/step - loss: 0.0524 - accuracy: 0.9856 - val_loss: 0.2262 - val_accuracy: 0.9331\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.92369 to 0.93307, saving model to ../model/hi_weights.best.hdf5\n",
      "Epoch 7/10\n",
      "6717/6717 [==============================] - 8s 1ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.2343 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.93307\n",
      "Epoch 8/10\n",
      "6717/6717 [==============================] - 7s 1ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.2266 - val_accuracy: 0.9331\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.93307\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/hi_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi-Code Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'text_id', 'ekphrasis_clean_text', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_hi_cdmx = pd.read_csv('../data/dataset_hi_cdmx.csv')\n",
    "df_hi_cdmx[\"class\"] = df_hi_cdmx[\"class\"].astype(int)\n",
    "df_hi_cdmx = df_hi_cdmx.dropna() # drop any rotokenizer_testws with nans\n",
    "df_hi_cdmx = df_hi_cdmx.drop(['text'],axis=1)\n",
    "df_hi_cdmx = df_hi_cdmx.rename(columns={'basic_clean_text':'text'})\n",
    "print(df_hi_cdmx.columns)\n",
    "df_hi_cdmx.drop(df_hi_cdmx.loc[df_hi_cdmx['text_id'] == 'text_id'].index,inplace=True)\n",
    "df_hi_cdmx.drop(df_hi_cdmx.loc[df_hi_cdmx['class'] == 'HS'].index,inplace=True)\n",
    "df_hi_cdmx['text_len'] = df_hi_cdmx.apply(lambda x: len(x.text.split()), axis=1)\n",
    "df_hi_cdmx = df_hi_cdmx[df_hi_cdmx['text_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3161/3161 [00:01<00:00, 1771.48it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ProcessData(df_hi_cdmx, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6020, array([2, 0, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_seq_len, data.vocab_size, data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 16)            96320     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 128)           10368     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                5560      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 112,281\n",
      "Trainable params: 112,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = network(seed=30, epochs=10, batch_size=30, optimiser='adam')\n",
    "model = net.get_model(classes=len(data.classes), vocabulary_size=data.vocab_size, input_length=data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2275 samples, validate on 253 samples\n",
      "Epoch 1/10\n",
      "2275/2275 [==============================] - 1s 447us/step - loss: 0.9404 - accuracy: 0.5534 - val_loss: 0.8710 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58893, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 2/10\n",
      "2275/2275 [==============================] - 1s 254us/step - loss: 0.7870 - accuracy: 0.6501 - val_loss: 0.7575 - val_accuracy: 0.8024\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.58893 to 0.80237, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 3/10\n",
      "2275/2275 [==============================] - 1s 283us/step - loss: 0.4265 - accuracy: 0.8633 - val_loss: 0.5636 - val_accuracy: 0.8379\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.80237 to 0.83794, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 4/10\n",
      "2275/2275 [==============================] - 1s 236us/step - loss: 0.2349 - accuracy: 0.9481 - val_loss: 0.6077 - val_accuracy: 0.7747\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.83794\n",
      "Epoch 5/10\n",
      "2275/2275 [==============================] - 1s 246us/step - loss: 0.1511 - accuracy: 0.9793 - val_loss: 0.4520 - val_accuracy: 0.8577\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.83794 to 0.85771, saving model to ../model/hi_cdmx_weights.best.hdf5\n",
      "Epoch 6/10\n",
      "2275/2275 [==============================] - 1s 248us/step - loss: 0.1026 - accuracy: 0.9881 - val_loss: 0.4295 - val_accuracy: 0.8379\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.85771\n",
      "Epoch 7/10\n",
      "2275/2275 [==============================] - 1s 235us/step - loss: 0.0796 - accuracy: 0.9886 - val_loss: 0.4155 - val_accuracy: 0.8577\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.85771\n",
      "Epoch 8/10\n",
      "2275/2275 [==============================] - 1s 263us/step - loss: 0.0629 - accuracy: 0.9934 - val_loss: 0.5015 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.85771\n",
      "Epoch 9/10\n",
      "2275/2275 [==============================] - 1s 255us/step - loss: 0.0486 - accuracy: 0.9952 - val_loss: 0.4327 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.85771\n",
      "Epoch 10/10\n",
      "2275/2275 [==============================] - 1s 247us/step - loss: 0.0399 - accuracy: 0.9974 - val_loss: 0.4211 - val_accuracy: 0.8538\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.85771\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/hi_cdmx_weights.best.hdf5'\n",
    "model = net.train(data.X_train, data.y_train, model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
